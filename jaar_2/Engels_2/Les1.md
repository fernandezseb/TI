# 1.1 Troll hunters: the Twitterbots that fight against online abuse
## 1.1.1 Vocabulary

| Word | Explanation/Translation |
| ---: | --- |
| Mistogynistic | Sexist, men who hate women |
| Decried (to decry) | Denounce, condemn, publicly callout, "aanklagen' |
| To curb | Reduce |
| Proactive | Taking initiative, try to prevent |
| Hassle |  A lot of trouble |
| (to) Trawl (through) | Move through with a lot of effort |
| Invective | Rude and insulting words that someone says when they are very angry |
| Hit a snag | A problem or disadvantage, one that is not very serious, which you hadn't expected |
| Torrent | A lot of words spoken quickly, especially insulting or criticizing someone. (Literally a floud of water.) |
| Mishmash | Mixture, hodge-podge, "mengelmoes" |
| Affiliate | To join or become connected with a large group or organization |
| Malicious | With bad intention, very unkind or cruel |
| Admonish | To tell someone severely that they have done something wrong |
| Unnverving | To upset or frishten someone so that they lose their confidence or ability to thinkg clearly |

## 1.1.2 Comprehension

* Explain the following quote that was left out of the text and provide 2 examples: “… methods to deflect abuse and manipulate behaviour could themselves be abused”.
> * These methods could be used for e.g. a government to control the people such as in some autocratic countries.
> * People could start using words that can have different meanings depending on the context to confuse automated systems. E.g. te words 'bitch' and 'whore' are widespread words that are also used in natural chat.

* Explain how Munger lowered the number of racist comments on Twitter. What method did he use? Could it be used to get rid of all online racism? Why (not)?
> He created bots that impersonated different types of people. These bots were created to admonish people tweeting racist comments. His methods reduced the amount but couldn't get rid of all of them because it didn't affect the commited racists (much).

* Explain: “The more people become aware that these are out there, the less effective they’ll be”
> Once people know wich accounts are bots, they won't listen to them anymore. Moreover, it will eventually even turn out to increase racism because they will try to fight back against the bots.

## 1.1.3 Discussion-assignment

* Do you think that it is up to the companies (Twitter/Facebook/…) to make sure there is no verbal abuse on their site?
> They should help by fighting against verbal abuse, but they shouldn't be held responsible for the actions of other people using their platform. They can't and shouldn't be asked to guarantee that no such things will happen on their service.

* Is it ethical to have a bot pose as a human? What could be the repercussions?
> At the moment it is more or less clear when the person behind the account is a bot, but I think it would be better if the service would force people to indicate on the account that it is a bot. The repercussions would be that people could start a friendship with somebody that turns out to be a bot and then the person will feel bad because he/she was tricked.

* According to New York University researcher Zeynep Tufecki, there are now cases against about 2000 people for insulting the Turkish president online. If bots can be misused like this, do you think that they should be developed further?
> I don't think that we shouldn't use a technique that can fight abuse because it could be abused by certain governments, because the real problem is the government itself. Anything could be misused if it falls in the wrong hands.

* Literature question: the author says that “Turkey’s government has been accused of monitoring Twitter for thoughtcrimes”. Which novel does the word “thoughtcrime” refer to and why is it relevant here?
> It refers to the novel Nineteen Eighty-Four from George Orwell. Just like in Turkey in the book there is a government that tries to control people by using technology that interprets what people write (in the case of Twitter) or think (in the novel).
